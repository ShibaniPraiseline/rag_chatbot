# RAG Chatbot using FastAPI and FAISS

A simple Retrieval-Augmented Generation (RAG) system that allows users to query documents and receive context-aware answers using vector search and large language models.

## ğŸ“Œ Project Overview

This project implements a basic Retrieval-Augmented Generation (RAG) pipeline using Python.  
It enables users to ask questions over provided documents by retrieving relevant chunks using vector similarity search and generating answers grounded in the retrieved content.

## â“ Problem Statement

Large Language Models (LLMs) often generate incorrect or hallucinated answers when they do not have access to domain-specific knowledge.  
This project addresses that issue by retrieving relevant information from documents before generating responses, ensuring answers are context-aware and fact-based.

## ğŸ—ï¸ System Architecture

The system follows a standard RAG workflow:

1. Documents are loaded and split into smaller chunks  
2. Each chunk is converted into vector embeddings  
3. Embeddings are stored in a FAISS vector index  
4. User queries are embedded and matched against stored vectors  
5. The most relevant chunks are sent to the language model  
6. The model generates an answer based on retrieved context  

## ğŸ§© Architecture Diagram

### Query-Time Flow
User â†’ FastAPI â†’ FAISS Retriever â†’ Context Chunks â†’ Answer Generator â†’ Response

### Indexing Flow
Document â†’ Loader â†’ Chunker â†’ Embeddings â†’ FAISS Index

**Flow:**

User Query  
â†’ FastAPI Backend  
â†’ Vector Retriever (FAISS)  
â†’ Relevant Document Chunks  
â†’ Answer Generator (LLM)  
â†’ Final Response

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- FastAPI
- FAISS
- Sentence Transformers
- Uvicorn

## ğŸ“‚ Project Structure

rag_chatbot/
â”œâ”€â”€ app.py # FastAPI entry point
â”œâ”€â”€ ingest/
â”‚ â”œâ”€â”€ loader.py # Document loading
â”‚ â”œâ”€â”€ chunker.py # Text chunking
â”‚ â””â”€â”€ retriever.py # FAISS-based retrieval
â”œâ”€â”€ rag/
â”‚ â””â”€â”€ generator.py # Answer generation
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample.pdf # Example document
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot
Create and activate a virtual environment:

bash
Copy code
python -m venv venv
venv\Scripts\activate   # Windows
Install dependencies:

bash
Copy code
pip install -r requirements.txt
â–¶ï¸ Running the Application
Start the FastAPI server:

bash
Copy code
uvicorn app:app --reload
The API will be available at:
http://127.0.0.1:8000

API documentation (Swagger UI):
http://127.0.0.1:8000/docs

ğŸ§ª Example Usage
Provide a document (PDF)

Ask a question related to the document

The system retrieves relevant content and generates a grounded response

ğŸ“ Learning Outcomes
Understanding of Retrieval-Augmented Generation (RAG)

Working with vector embeddings and FAISS

Building APIs using FastAPI

Structuring a machine learning backend project

Managing Python virtual environments

